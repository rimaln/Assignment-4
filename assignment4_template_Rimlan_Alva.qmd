---
title: "Goodreads Books Dataset Overview and Author’s Notes"
subtitle: "Assignment 4 ETC5512"
author: "Rimlan Alva"
format: html
editor: visual
---

::: panel-tabset
<!-- Task 1 Tab: Data and Documenting -->

## Data and Documenting

### What's in this section

1.  Can we recommend high-quality books based on community preferences? 
 In particular, I aim to explore how average ratings, rating count, genre, and authorship influence what books we might recommend. I chose this because I'm an avid reader and have always wanted to see if a data-driven approach could suggest books I might love but haven’t discovered.
 
2. For this project, I’m using a Goodreads dataset that includes detailed metadata on thousands of books—such as titles, authors, average ratings, rating counts, publishers, and publication dates. Originally scraped and shared on Kaggle, it was curated to support book recommendation systems, making it well-suited for analyzing reader preferences and identifying top-rated books.

This dataset is highly suitable for my task for several reasons:

- **Rich in Numeric and Categorical Variables:**
It includes average ratings (1–5 scale), number of ratings, and publication details — which are essential for ranking and filtering books.

- **Well-Structured:**
The dataset is clean and consolidated into a single file, with minimal preprocessing needed compared to many other book datasets.

- **Supports Recommendation Use Cases:**
With user rating aggregates and author/book metadata, I can analyze trends, identify top books in each genre or by rating, and simulate a basic recommendation approach.

- **Ethically Acceptable:**
The dataset contains no personal user data — only aggregated ratings and book details — making it appropriate for educational and analytical use.

- **Aligned with My Question:**
Since my question revolves around identifying and recommending highly-rated books, this dataset provides exactly the type of information I need to evaluate book popularity and reader preferences.

3. *Data Type*
- The dataset is **observational sample data**, compiled through web scraping of publicly available book information on Goodreads.
- It is **not experimental**; rather, it is an aggregate of user ratings and book details collected over time.
- It can be considered a **sample** of books from Goodreads rather than a complete census of all published books.

- *Data Dictionary*

| Variable Name      | Description                              | Data Type          |
|--------------------|------------------------------------------|--------------------|
| `title`            | Title of the book                        | Categorical (text) |
| `author`           | Name of the author                       | Categorical (text) |
| `average_rating`   | Average user rating (scale 1 to 5)       | Numeric (float)     |
| `ratings_count`    | Number of user ratings                    | Numeric (integer)   |
| `publisher`        | Publisher of the book                    | Categorical (text) |
| `publication_date` | Date when the book was published         | Date / Categorical  |
| `genre`            | Genre or category of the book (if present) | Categorical (text) |

*Data Limitations*

- The dataset reflects **only books listed and rated on Goodreads**, which may introduce bias toward more popular or English-language titles.
- The ratings are **aggregated user ratings**, which may be subject to biases such as popularity bias or rating inflation.
- Some fields, such as genre or publication date, may have **missing or inconsistent values**.
- The dataset may not fully represent all book markets or reader demographics worldwide.

*Data Privacy and Ethical Considerations*

- The dataset contains **no personally identifiable information (PII)** or individual user data; only aggregated ratings and book metadata are included.
- Use of this dataset is **ethically appropriate for educational and analytical purposes**.
- Since the data is publicly available and anonymized, there are no privacy risks associated with its use.
- I acknowledge the importance of using data responsibly and transparently, avoiding misrepresentation or over-generalization based on this sample.

4. *Data Download and Processing Steps*

i. *Download the Dataset*

- The dataset is publicly available on Kaggle.  
- Visit the dataset page at: [https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks]
- Sign in or create a free Kaggle account if you don’t have one.  
- Click the **Download** button to download the dataset ZIP file.

ii. *Extract the Files*

- Unzip the downloaded dataset folder to a working directory on your computer.  
- The dataset is usually provided as a CSV file (e.g., `books.csv`).

iii. *Load the Data*

- Load the CSV file into your analysis environment using appropriate commands.
```{r}
goodreads_data <- read.csv("data/books.csv", stringsAsFactors = FALSE)
```

- This loads book metadata including titles, authors, average ratings, number of ratings, publishers, and publication dates.

iv. *Initial Processing*
- Convert average_rating and num_pages from character to numeric.
- Parse publication_date into a proper Date format.
- Remove rows with missing or invalid values in critical fields such as average_rating.
- Split multiple authors if required (delimited by /).


v. *Data Cleaning Steps*
To prepare the data for analysis:
```{r}
# Convert relevant columns to numeric
goodreads_data$average_rating <- as.numeric(goodreads_data$average_rating)
goodreads_data$num_pages <- as.numeric(goodreads_data$num_pages)

# Convert publication date to Date format
goodreads_data$publication_date <- as.Date(goodreads_data$publication_date, format = "%m/%d/%Y")

# Remove rows with missing or invalid average ratings
goodreads_data <- goodreads_data[!is.na(goodreads_data$average_rating), ]
```

vi. *Other Datasets Used*
No additional datasets were used in this analysis. All findings and insights are based on this single source.


### Remember
All analysis and documentation refer to the Goodreads dataset provided in the data/ folder.

For further clarity, a copy of this dataset's metadata and original source is documented in this report under the About Dataset section.

<!-- Task 2 Tab: Writing your blogpost -->

## Blog post

### What's in this section

Here is where you should write your blogpost! (Task 2)

### Blogpost Structure

1.  Title : Goodreads Books Dataset Overview and Author’s Notes

2.  Motivation:  As an avid reader, I often wonder what makes a book truly worth reading. Can data from a large community of readers help us identify high-quality books? This blog post explores the Goodreads Books dataset to answer:

- How do average ratings relate to the number of ratings a book receives?
- Are certain authors consistently producing higher-rated books?
- Does the length of a book (page count) affect its average rating?

By investigating these questions, I aim to uncover insights into book popularity and quality from a data-driven perspective.

3.  Data: The dataset I’m using contains detailed metadata for over 11,000 books from Goodreads, including titles, authors, average ratings, rating counts, publishers, publication dates, and page counts. It was originally scraped and shared on Kaggle, making it ideal for analyzing reader preferences and identifying top-rated books. 

The data includes numeric variables (average_rating, ratings_count, num_pages) and categorical variables (authors, publisher, genre). This combination allows a multifaceted exploration of what makes a book worth recommending.

4.  Analysis : 
```{r}
library(tidyverse)
library(dplyr)

# Load data
goodreads_data <- read.csv("data/books.csv", stringsAsFactors = FALSE)

# Data cleaning
goodreads_data <- goodreads_data %>%
  filter(!is.na(as.numeric(average_rating))) %>%
  mutate(
    average_rating = as.numeric(average_rating),
    num_pages = as.numeric(num_pages),
    publication_date = as.Date(publication_date, format = "%m/%d/%Y")
  )
```

**Author Influence**
```{r}
library(ggplot2)
library(tidyr)

# Preprocess: select authors with >= 5 books
top_authors <- goodreads_data %>%
  tidyr::separate_rows(authors, sep = "/") %>%
  group_by(authors) %>%
  filter(n() >= 5) %>%
  ungroup()

top8 <- top_authors %>%
  count(authors, sort = TRUE) %>%
  slice_head(n = 8) %>%
  pull(authors)

# Filter again for top 8 authors only
violin_data <- top_authors %>%
  filter(authors %in% top8)

# Violin plot
ggplot(violin_data, aes(x = reorder(authors, average_rating, FUN = median), y = average_rating, fill = authors)) +
  geom_violin(color = "gray20", alpha = 0.8) +
  geom_boxplot(width = 0.1, outlier.shape = NA, fill = "white", color = "black") +
  scale_fill_brewer(palette = "PuBuGn") +
  labs(
    title = "Distribution of Average Ratings for Top Authors",
    x = "Author",
    y = "Average Rating"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )
```

**Popularity and Ratings**
```{r}
library(scales)

ggplot(goodreads_data, aes(x = ratings_count, y = average_rating)) +
  geom_point(aes(size = num_pages, color = average_rating), alpha = 0.5) +
  scale_x_log10(labels = comma) +
  scale_size_continuous(range = c(1, 10), breaks = c(100, 300, 600, 1000)) +
  scale_color_viridis_c(option = "C", limits = c(3, 5)) +
  labs(
    title = "Bubble Plot: Average Rating vs Ratings Count",
    x = "Ratings Count (log scale)",
    y = "Average Rating",
    color = "Avg Rating",
    size = "Page Count"
  ) +
  theme_minimal()
```

5.  Conclusions\
6.  References

<!-- Task 3 Tab: Behind the Scenes -  -->

## Behind the Scenes

### What's in this section

Here is where you should tell us about your reflection on your analysis (Task 3).

Again, these are the details about **your** perspective and the gritty details behind the scenes of your analysis.
:::
